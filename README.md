# ChromeChat

**Version:** 0.1.0

**Description:**
ChromeChat is a Chrome extension (Manifest V3) that enables users to interact with local or cloud-based Ollama models directly from a popup or sidebar within the browser.

**Features:**
- **Interactive Chat:** Engage in conversations with Ollama models via a popup or sidebar.
- **Streaming and Non-Streaming Responses:** Supports both streaming and non-streaming modes with typewriter effect.
- **Session Management:** Create, read, update, delete, export, and import chat sessions.
- **Automatic Summarization and Context Truncation:** Summarizes conversations and manages context length.
- **Page Content Integration:** Fetches the main content of the current page and sends it as a user message.
- **Stop Generation:** Allows interruption of ongoing responses.

**Directory Structure:**
- `popup.html` / `popup.css` / `popup.js`: Handles the popup UI and frontend logic, including session management, input/output, model selection, and settings.
- `sidebar.html` / `content_sidebar_inject.js`: Manages the sidebar UI and injection logic.
- `background.js`: Acts as the Service Worker, handling network interactions with Ollama, streaming parsing, summarization, and message bridging.
- `content_fetch.js`: Injected into web pages to extract main content for user messages.
- `manifest.json`: Defines extension metadata and permissions.
- `icons/`: Contains extension icons.
- `styles/`: Includes shared CSS styles.
- `locales/`: Provides localization files for multiple languages.

**Installation:**
1. Clone the repository.
2. Open Chrome and navigate to `chrome://extensions/`.
3. Enable "Developer mode" (toggle switch in the top right corner).
4. Click "Load unpacked" and select the cloned repository folder.

**Usage:**
- Click the ChromeChat icon in the toolbar to open the popup.
- Use the sidebar handle to open/close the sidebar.
- Configure settings to connect to local or cloud-based Ollama models.
- Start a new session or continue an existing one to chat with the model.

**Configuration:**
- **Local Ollama Model:**
  - Ensure Ollama is running locally and accessible.
  - Set the API endpoint in the extension settings.
- **Cloud Ollama Model:**
  - Obtain an API key from the Ollama cloud service.
  - Enter the API key in the extension settings.

**Known Issues:**
- **CORS Errors:** Ensure `OLLAMA_ORIGINS` includes the extension's origin and restart Ollama.
- **Response Body Unavailable:** Switch to non-streaming mode to retrieve the full JSON response.
- **Injection Failures:** Some Chrome internal pages or the Web Store may block script injection; the extension checks for injectable URLs.

**Security Considerations:**
- Avoid setting `OLLAMA_ORIGINS` to `*` in production.
- Store the Ollama API Key securely and remove it when not needed.
- If exposing Ollama to the LAN, configure firewall rules to restrict access.

**Changelog:**
- **2025-10-03:** Fixed message persistence order; introduced write lock.
- **2025-10-05:** Added support for Ollama cloud API Key configuration and injected Authorization in requests.
- **2025-10-06:** Introduced light glassmorphism UI.
- **2025-10-07:** Added "Stop Generation" feature; injected sidebar handle to open/close the sidebar.

**To-Do and Suggestions:**
- Integrate a tokenizer library for accurate token counting.
- Improve streaming compatibility: explore MessageChannel or local proxy for reliable NDJSON transmission.
- Provide optional Ollama startup scripts/services to simplify environment variable configuration on Windows startup.

*This README was generated by an AI assistant on 2025-10-08 and written with user confirmation.*


